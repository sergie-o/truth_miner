{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9105970",
   "metadata": {},
   "source": [
    "# <span style=\"color: #CCFF00;\">Project TruthMiner - Mining through headlines to uncover real vs fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98875ef1",
   "metadata": {},
   "source": [
    "## <span style=\"color: #98FF98;\">📌 Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843cd44",
   "metadata": {},
   "source": [
    "TruthMiner is a Natural Language Processing (NLP) project that focuses on classifying news headlines as either **real (1)** or **fake (0)**.  \n",
    "The goal is to build a robust machine learning pipeline that can process raw text, extract meaningful features, and accurately distinguish between authentic and fabricated news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fada62",
   "metadata": {},
   "source": [
    "### <span style=\"color: #77DD77;\">Main Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9e544",
   "metadata": {},
   "source": [
    "\n",
    "1. **Text Preprocessing & Feature Engineering**  \n",
    "   - Clean and transform raw news headlines (remove stopwords, punctuation, apply stemming/lemmatization, and vectorize text using TF-IDF or Bag-of-Words).\n",
    "\n",
    "2. **Model Development**  \n",
    "   - Build and train a classifier (e.g., Logistic Regression, Naïve Bayes, SVM, Random Forest, or deep learning) to distinguish between real and fake headlines.\n",
    "\n",
    "3. **Prediction on Unseen Data**  \n",
    "   - Apply the trained model to `testing_data.csv`, replacing placeholder labels (`2`) with predicted labels (`0` = fake, `1` = real).\n",
    "\n",
    "4. **Evaluation & Accuracy Estimation**  \n",
    "   - Evaluate performance using metrics such as Accuracy, Precision, Recall, and F1-score.  \n",
    "   - Provide an estimation of how well the model is expected to perform in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dab6f1",
   "metadata": {},
   "source": [
    "## <span style=\"color: #FFD1DC;\"> Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d77432ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Models and Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2963e9",
   "metadata": {},
   "source": [
    "## <span style=\"color: #00FFFF;\"> Training Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ed244",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">Loading the Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93daad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(r\"C:\\DSML bootcamp\\Week7\\project-3-nlp\\dataset\\training_data.csv\", sep=\"\\t\", header=None, names=[\"label\", \"headline\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "774b8ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump sends out embarrassing new year‚s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is so obsessed he even has obama‚s name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34147</th>\n",
       "      <td>1</td>\n",
       "      <td>tears in rain as thais gather for late king's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34148</th>\n",
       "      <td>1</td>\n",
       "      <td>pyongyang university needs non-u.s. teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34149</th>\n",
       "      <td>1</td>\n",
       "      <td>philippine president duterte to visit japan ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34150</th>\n",
       "      <td>1</td>\n",
       "      <td>japan's abe may have won election\\tbut many do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34151</th>\n",
       "      <td>1</td>\n",
       "      <td>demoralized and divided: inside catalonia's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           headline\n",
       "0          0  donald trump sends out embarrassing new year‚s...\n",
       "1          0  drunk bragging trump staffer started russian c...\n",
       "2          0  sheriff david clarke becomes an internet joke ...\n",
       "3          0  trump is so obsessed he even has obama‚s name ...\n",
       "4          0  pope francis just called out donald trump duri...\n",
       "...      ...                                                ...\n",
       "34147      1  tears in rain as thais gather for late king's ...\n",
       "34148      1  pyongyang university needs non-u.s. teachers a...\n",
       "34149      1  philippine president duterte to visit japan ah...\n",
       "34150      1  japan's abe may have won election\\tbut many do...\n",
       "34151      1  demoralized and divided: inside catalonia's po...\n",
       "\n",
       "[34152 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ee64c",
   "metadata": {},
   "source": [
    "* After viewing the data here , the next step is to split the data into training and test partitions. We already have a different csv file for final prediction after picking the best model but then splitting the data here into training and validation data helps in estimating accuracy before the final submission. \n",
    "* So in this development phase of the model , we will train on X_train and validate on X_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e5d0e",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">X y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7d30c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_train[\"headline\"]\n",
    "y=data_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c966bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(data_train[\"headline\"], data_train[\"label\"], test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0ce79",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09eb0e",
   "metadata": {},
   "source": [
    "This process involves cleaning and normalizing raw text.  \n",
    "In other words, it transforms messy raw text into a cleaned text batch.  \n",
    "\n",
    "**Purpose:** Make text consistent and remove noise.  \n",
    "\n",
    " 🔄 Pipeline\n",
    "\n",
    "- **Input:** Raw messy text  \n",
    "- **Output:** Clean, normalized text (still text!)\n",
    "\n",
    "**Steps:**\n",
    "1. Convert all text to **lowercase**  \n",
    "2. Remove **punctuation** (where necessary)  \n",
    "3. Perform **tokenization** (break sentences into words)  \n",
    "4. Remove **stopwords** (common words like *the, is, and*)  \n",
    "5. Apply **stemming** and/or **lemmatization** to reduce words to their root form  \n",
    "6. Obtain **cleaned text**\n",
    "\n",
    "```python\n",
    "text = text.lower()                          # ✅ Preprocessing\n",
    "text = remove_punctuation(text)              # ✅ Preprocessing\n",
    "tokens = tokenize(text)                      # ✅ Preprocessing\n",
    "tokens = remove_stopwords(tokens)            # ✅ Preprocessing\n",
    "tokens = apply_stemming(tokens)              # ✅ Preprocessing\n",
    "clean_text = ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d8257f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample headlines by class:\n",
      "\n",
      "--- Class 0 samples ---\n",
      "1: 'donald trump sends out embarrassing new year‚s eve message; this is disturbing'\n",
      "2: 'drunk bragging trump staffer started russian collusion investigation'\n",
      "3: 'sheriff david clarke becomes an internet joke for threatening to poke people ‚in the eye‚'\n",
      "\n",
      "--- Class 1 samples ---\n",
      "1: 'as u.s. budget fight looms\trepublicans flip their fiscal script'\n",
      "2: 'u.s. military to accept transgender recruits on monday: pentagon'\n",
      "3: 'senior u.s. republican senator: 'let mr. mueller do his job''\n"
     ]
    }
   ],
   "source": [
    "# Look at actual text samples\n",
    "print(\"Sample headlines by class:\")\n",
    "\n",
    "for label in data_train['label'].unique():\n",
    "    print(f\"\\n--- Class {label} samples ---\")\n",
    "    \n",
    "    samples = data_train[data_train['label'] == label]['headline'].head(3)\n",
    "    for i, headline in enumerate(samples, 1):\n",
    "        print(f\"{i}: '{headline}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "150dfb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "label       0\n",
      "headline    0\n",
      "dtype: int64\n",
      "Null headlines: 0\n",
      "Empty headlines: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(data_train.isnull().sum())\n",
    "\n",
    "# Handle missing text\n",
    "print(f\"Null headlines: {data_train['headline'].isnull().sum()}\")\n",
    "print(f\"Empty headlines: {(data_train['headline'] == '').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cabb820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_single_headline(text):\n",
    "    \"\"\"Clean individual headline text\"\"\"\n",
    "    \n",
    "    # Handle missing values\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Ensure string type\n",
    "    text = str(text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Fix whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Handle excessive punctuation\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "\n",
    "\n",
    "    # Step 8: REMOVE STOPWORDS\n",
    "    # Tokenize first\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Get English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join back into text\n",
    "    text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    \n",
    "    # Expand contractions\n",
    "    contractions = {\n",
    "        \"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\",\n",
    "        \"'re\": \" are\", \"'ve\": \" have\", \"'ll\": \" will\",\n",
    "        \"'d\": \" would\", \"'m\": \" am\"\n",
    "    }\n",
    "    \n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f18b9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"headline_cleaned\"]=data_train[\"headline\"].apply(clean_single_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d2d7946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "      <th>headline_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump sends out embarrassing new year‚s...</td>\n",
       "      <td>donald trump sends embarrassing new year‚s eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>sheriff david clarke becomes internet joke thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is so obsessed he even has obama‚s name ...</td>\n",
       "      <td>trump obsessed even obama‚s name coded website...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>pope francis called donald trump christmas speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34147</th>\n",
       "      <td>1</td>\n",
       "      <td>tears in rain as thais gather for late king's ...</td>\n",
       "      <td>tears rain thais gather late king 's funeral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34148</th>\n",
       "      <td>1</td>\n",
       "      <td>pyongyang university needs non-u.s. teachers a...</td>\n",
       "      <td>pyongyang university needs non-u.s. teachers t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34149</th>\n",
       "      <td>1</td>\n",
       "      <td>philippine president duterte to visit japan ah...</td>\n",
       "      <td>philippine president duterte visit japan ahead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34150</th>\n",
       "      <td>1</td>\n",
       "      <td>japan's abe may have won election\\tbut many do...</td>\n",
       "      <td>japan 's abe may election many  not want pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34151</th>\n",
       "      <td>1</td>\n",
       "      <td>demoralized and divided: inside catalonia's po...</td>\n",
       "      <td>demoralized divided : inside catalonia 's poli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           headline  \\\n",
       "0          0  donald trump sends out embarrassing new year‚s...   \n",
       "1          0  drunk bragging trump staffer started russian c...   \n",
       "2          0  sheriff david clarke becomes an internet joke ...   \n",
       "3          0  trump is so obsessed he even has obama‚s name ...   \n",
       "4          0  pope francis just called out donald trump duri...   \n",
       "...      ...                                                ...   \n",
       "34147      1  tears in rain as thais gather for late king's ...   \n",
       "34148      1  pyongyang university needs non-u.s. teachers a...   \n",
       "34149      1  philippine president duterte to visit japan ah...   \n",
       "34150      1  japan's abe may have won election\\tbut many do...   \n",
       "34151      1  demoralized and divided: inside catalonia's po...   \n",
       "\n",
       "                                        headline_cleaned  \n",
       "0      donald trump sends embarrassing new year‚s eve...  \n",
       "1      drunk bragging trump staffer started russian c...  \n",
       "2      sheriff david clarke becomes internet joke thr...  \n",
       "3      trump obsessed even obama‚s name coded website...  \n",
       "4      pope francis called donald trump christmas speech  \n",
       "...                                                  ...  \n",
       "34147       tears rain thais gather late king 's funeral  \n",
       "34148  pyongyang university needs non-u.s. teachers t...  \n",
       "34149  philippine president duterte visit japan ahead...  \n",
       "34150        japan 's abe may election many  not want pm  \n",
       "34151  demoralized divided : inside catalonia 's poli...  \n",
       "\n",
       "[34152 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7857709",
   "metadata": {},
   "source": [
    "-   The headlines show very little differences after implementing the text cleaning.In order to verify this we can create a function to see both cleaned and original headlines to see if there are any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e02a1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_comparison(dataframe, num_samples=5):\n",
    "    \"\"\"\n",
    "    Show original vs cleaned headlines side by side\n",
    "    \"\"\"\n",
    "    print(\"🔍 VISUAL COMPARISON - Original vs Cleaned\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataframe))):\n",
    "        original = dataframe['headline'].iloc[i]\n",
    "        cleaned = dataframe['headline_cleaned'].iloc[i]\n",
    "        label = dataframe['label'].iloc[i]\n",
    "        \n",
    "        # Show if anything changed\n",
    "        changed = \"CHANGED\" if original != cleaned else \" NO CHANGE\"\n",
    "        \n",
    "        print(f\"\\n📰 Sample {i+1} (Label: {label}) - {changed}\")\n",
    "        print(f\"Original:  '{original}'\")\n",
    "        print(f\"Cleaned:   '{cleaned}'\")\n",
    "        \n",
    "        # Show specific differences\n",
    "        if original != cleaned:\n",
    "            print(f\"Length:    {len(original)} → {len(cleaned)} chars\")\n",
    "            print(f\"Words:     {len(original.split())} → {len(cleaned.split())} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6707fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VISUAL COMPARISON - Original vs Cleaned\n",
      "================================================================================\n",
      "\n",
      "📰 Sample 1 (Label: 0) - CHANGED\n",
      "Original:  'donald trump sends out embarrassing new year‚s eve message; this is disturbing'\n",
      "Cleaned:   'donald trump sends embarrassing new year‚s eve message ; disturbing'\n",
      "Length:    78 → 67 chars\n",
      "Words:     12 → 10 words\n",
      "\n",
      "📰 Sample 2 (Label: 0) -  NO CHANGE\n",
      "Original:  'drunk bragging trump staffer started russian collusion investigation'\n",
      "Cleaned:   'drunk bragging trump staffer started russian collusion investigation'\n",
      "\n",
      "📰 Sample 3 (Label: 0) - CHANGED\n",
      "Original:  'sheriff david clarke becomes an internet joke for threatening to poke people ‚in the eye‚'\n",
      "Cleaned:   'sheriff david clarke becomes internet joke threatening poke people ‚in eye‚'\n",
      "Length:    89 → 75 chars\n",
      "Words:     15 → 11 words\n",
      "\n",
      "📰 Sample 4 (Label: 0) - CHANGED\n",
      "Original:  'trump is so obsessed he even has obama‚s name coded into his website (images)'\n",
      "Cleaned:   'trump obsessed even obama‚s name coded website ( images )'\n",
      "Length:    77 → 57 chars\n",
      "Words:     14 → 10 words\n",
      "\n",
      "📰 Sample 5 (Label: 0) - CHANGED\n",
      "Original:  'pope francis just called out donald trump during his christmas speech'\n",
      "Cleaned:   'pope francis called donald trump christmas speech'\n",
      "Length:    69 → 49 chars\n",
      "Words:     11 → 7 words\n"
     ]
    }
   ],
   "source": [
    "visual_comparison(data_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f160c5",
   "metadata": {},
   "source": [
    "-   This proves the texts are already clean so we can move on to the next step which is Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49948d",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\"> Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f9486",
   "metadata": {},
   "source": [
    "\n",
    "Feature Engineering transforms cleaned text into numerical representations  \n",
    "that machine learning models can understand and process.  \n",
    "\n",
    "- **Input:** Clean text  \n",
    "- **Output:** Numerical vectors or matrices  \n",
    "- **Purpose:** Convert text into a format suitable for ML models  \n",
    "\n",
    " 🔄 Pipeline\n",
    "\n",
    "**Clean Text → Numerical Representation**\n",
    "\n",
    "Common techniques include:  \n",
    "1. **Bag of Words (BoW)** – word counts in a document  \n",
    "2. **TF-IDF (Term Frequency–Inverse Document Frequency)** – weighted word importance  \n",
    "3. **Word Embeddings** (e.g., Word2Vec, GloVe, FastText) – semantic vector representations  \n",
    "4. **Transformer Embeddings** (e.g., BERT, GPT) – contextualized text representations  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3ff45",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b165df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Complete!\n",
      "Training features: (23906, 5000)\n",
      "Validation features: (10246, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF features\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english', \n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "\n",
    "print(f\"TF-IDF Complete!\")\n",
    "print(f\"Training features: {X_train_tfidf.shape}\")\n",
    "print(f\"Validation features: {X_val_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e834bbcb",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #89CFF0;\">Insights and Analysis of TF-IDF Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e287ad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 5000\n",
      "Sample features: ['10', '100', '100 days', '100 million', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '200', '2000', '2008', '2010', '2012', '2015']\n",
      "\n",
      "Top fake news words: ['trump', 'video', 'obama', 'hillary', 'just', 'donald', 'gop', 'clinton', 'donald trump', 'president']\n",
      "Top real news words: ['trump', 'says', 'house', 'russia', 'white house', 'white', 'senate', 'republican', 'china', 'tax']\n",
      "\n",
      "Fake news word scores:\n",
      "   'trump': 0.0454\n",
      "   'video': 0.0443\n",
      "   'obama': 0.0192\n",
      "   'hillary': 0.0188\n",
      "   'just': 0.0153\n",
      "\n",
      "Real news word scores:\n",
      "   'trump': 0.0371\n",
      "   'says': 0.0267\n",
      "   'house': 0.0186\n",
      "   'russia': 0.0123\n",
      "   'white house': 0.0120\n",
      "\n",
      "Words more distinctive to fake news (fake - real scores):\n",
      "   'video': fake=0.0443, real=0.0003, diff=0.0440\n",
      "   'hillary': fake=0.0188, real=0.0007, diff=0.0181\n",
      "   'just': fake=0.0153, real=0.0002, diff=0.0151\n",
      "   'obama': fake=0.0192, real=0.0086, diff=0.0106\n",
      "   'gop': fake=0.0105, real=0.0001, diff=0.0105\n",
      "\n",
      "Words more distinctive to real news (real - fake scores):\n",
      "   'says': fake=0.0038, real=0.0267, diff=-0.0228\n",
      "   'house': fake=0.0048, real=0.0186, diff=-0.0137\n",
      "   'senate': fake=0.0019, real=0.0114, diff=-0.0095\n",
      "   'china': fake=0.0006, real=0.0097, diff=-0.0091\n",
      "   'white house': fake=0.0033, real=0.0120, diff=-0.0087\n"
     ]
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "print(f\"Sample features: {list(feature_names[:20])}\")\n",
    "\n",
    "# Analyzing fake vs real word preferences:\n",
    "fake_indices = y_train == 0\n",
    "real_indices = y_train == 1\n",
    "\n",
    "# Convert to numpy arrays to avoid pandas/sparse matrix issues\n",
    "if hasattr(X_train_tfidf, 'toarray'):\n",
    "    # If it's a sparse matrix\n",
    "    X_train_array = X_train_tfidf.toarray()\n",
    "else:\n",
    "    # If it's already a dense array or DataFrame\n",
    "    X_train_array = np.array(X_train_tfidf)\n",
    "\n",
    "# Calculate means for fake and real news\n",
    "fake_means = X_train_array[fake_indices].mean(axis=0)\n",
    "real_means = X_train_array[real_indices].mean(axis=0)\n",
    "\n",
    "# Most distinctive fake news words:\n",
    "fake_top = fake_means.argsort()[-10:][::-1]\n",
    "print(\"\\nTop fake news words:\", [feature_names[i] for i in fake_top])\n",
    "\n",
    "# Most distinctive real news words:\n",
    "real_top = real_means.argsort()[-10:][::-1] \n",
    "print(\"Top real news words:\", [feature_names[i] for i in real_top])\n",
    "\n",
    "# Showing the actual TF-IDF scores for context:\n",
    "print(\"\\nFake news word scores:\")\n",
    "for i in fake_top[:5]:\n",
    "    print(f\"   '{feature_names[i]}': {fake_means[i]:.4f}\")\n",
    "\n",
    "print(\"\\nReal news word scores:\")  \n",
    "for i in real_top[:5]:\n",
    "    print(f\"   '{feature_names[i]}': {real_means[i]:.4f}\")\n",
    "\n",
    "# Optional: Show the difference between fake and real news word usage\n",
    "print(\"\\nWords more distinctive to fake news (fake - real scores):\")\n",
    "diff_scores = fake_means - real_means\n",
    "fake_distinctive = diff_scores.argsort()[-10:][::-1]\n",
    "for i in fake_distinctive[:5]:\n",
    "    print(f\"   '{feature_names[i]}': fake={fake_means[i]:.4f}, real={real_means[i]:.4f}, diff={diff_scores[i]:.4f}\")\n",
    "\n",
    "print(\"\\nWords more distinctive to real news (real - fake scores):\")\n",
    "real_distinctive = diff_scores.argsort()[:10]\n",
    "for i in real_distinctive[:5]:\n",
    "    print(f\"   '{feature_names[i]}': fake={fake_means[i]:.4f}, real={real_means[i]:.4f}, diff={diff_scores[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2d6e3",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\"> Models and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1142d86",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> Logical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae799213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9287526839742338\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      5272\n",
      "           1       0.91      0.94      0.93      4974\n",
      "\n",
      "    accuracy                           0.93     10246\n",
      "   macro avg       0.93      0.93      0.93     10246\n",
      "weighted avg       0.93      0.93      0.93     10246\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      " [[4831  441]\n",
      " [ 289 4685]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\" Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334309f8",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb40a0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9227991411282451\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      5272\n",
      "           1       0.93      0.91      0.92      4974\n",
      "\n",
      "    accuracy                           0.92     10246\n",
      "   macro avg       0.92      0.92      0.92     10246\n",
      "weighted avg       0.92      0.92      0.92     10246\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      " [[4922  350]\n",
      " [ 441 4533]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Naive Bayes (MultinomialNB is best for text data)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = nb.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\" Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1e086",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba5a52cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9133320320124927\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9186    0.9124    0.9155      5272\n",
      "           1     0.9078    0.9144    0.9111      4974\n",
      "\n",
      "    accuracy                         0.9133     10246\n",
      "   macro avg     0.9132    0.9134    0.9133     10246\n",
      "weighted avg     0.9134    0.9133    0.9133     10246\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      " [[4810  462]\n",
      " [ 426 4548]]\n"
     ]
    }
   ],
   "source": [
    "# ----- 1) Train -----\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,           # try 20–60 if you want to regularize\n",
    "    max_features=\"sqrt\",      # good default for high-dim TF-IDF\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"   # helps if classes are imbalanced; remove if not needed\n",
    ")\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# ----- 2) Validate -----\n",
    "y_pred = rf.predict(X_val_tfidf)\n",
    "print(\" Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_val, y_pred, digits=4))\n",
    "print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d12ea",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4f390183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9318758539918017\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9441    0.9222    0.9330      5272\n",
      "           1     0.9195    0.9421    0.9307      4974\n",
      "\n",
      "    accuracy                         0.9319     10246\n",
      "   macro avg     0.9318    0.9322    0.9319     10246\n",
      "weighted avg     0.9322    0.9319    0.9319     10246\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      " [[4862  410]\n",
      " [ 288 4686]]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "svm = LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42)  # set class_weight=None if balanced\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Validate\n",
    "y_pred = svm.predict(X_val_tfidf)\n",
    "print(\" Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_val, y_pred, digits=4))\n",
    "print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62dcc6",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "756ebec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Fake=12300, Real=11606\n",
      "Scale pos weight: 1.060\n"
     ]
    }
   ],
   "source": [
    "# Your code + evaluation:\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "scale_pos_weight = neg / pos if pos > 0 else 1.0\n",
    "\n",
    "print(f\"Class distribution: Fake={neg}, Real={pos}\")\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.3f}\")\n",
    "\n",
    "# Your XGBoost model (perfect as is!)\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d967262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;logloss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(1.0597966569016026)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0cc303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = xgb.predict(X_val_tfidf)\n",
    "y_pred_proba = xgb.predict_proba(X_val_tfidf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d8b1ea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88834667187195\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9456    0.8308    0.8845      5272\n",
      "           1     0.8411    0.9493    0.8920      4974\n",
      "\n",
      "    accuracy                         0.8883     10246\n",
      "   macro avg     0.8934    0.8901    0.8882     10246\n",
      "weighted avg     0.8949    0.8883    0.8881     10246\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      " [[4380  892]\n",
      " [ 252 4722]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_val, y_pred, digits=4))\n",
    "print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08964ba",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #FFE5B4;\"> Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "38e7c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(name, model, X_val, y_val):\n",
    "    \"\"\"Return accuracy, precision, recall, F1 for given model.\"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_val, y_pred, average=\"binary\", zero_division=0)\n",
    "    return {\"Model\": name, \"Accuracy\": acc, \"Precision\": p, \"Recall\": r, \"F1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b0819b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Logistic Regression...\n",
      " Training Naive Bayes...\n",
      " Training Random Forest...\n",
      " Training Linear SVM...\n",
      " Training XGBoost...\n",
      "\n",
      " MODEL PERFORMANCE RANKING (by Test Accuracy)\n",
      "============================================================\n",
      "              Model  Accuracy  Precision  Recall     F1\n",
      "         Linear SVM    0.9319     0.9195  0.9421 0.9307\n",
      "Logistic Regression    0.9277     0.9103  0.9441 0.9269\n",
      "        Naive Bayes    0.9233     0.9291  0.9115 0.9202\n",
      "      Random Forest    0.9133     0.9078  0.9144 0.9111\n",
      "            XGBoost    0.8751     0.8177  0.9558 0.8813\n",
      "\n",
      " BEST PERFORMING MODEL:\n",
      "   Model: Linear SVM\n",
      "   Test Accuracy: 0.9319\n",
      "   F1-Score: 0.9307\n"
     ]
    }
   ],
   "source": [
    "# Fit each model (using your existing X_train_tfidf, y_train)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42),\n",
    "    \"Naive Bayes\": MultinomialNB(alpha=0.5),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=400, max_depth=None, max_features=\"sqrt\", class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"Linear SVM\": LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        scale_pos_weight=((y_train==0).sum() / (y_train==1).sum())  # handles imbalance\n",
    "    )\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\" Training {name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    res = evaluate_model(name, model, X_val_tfidf, y_val)\n",
    "    results.append(res)\n",
    "\n",
    "# Convert to DataFrame and sort by Test Accuracy (highest first)\n",
    "df_results = pd.DataFrame(results).sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\n MODEL PERFORMANCE RANKING (by Test Accuracy)\")\n",
    "print(\"=\"*60)\n",
    "print(df_results.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Highlight the winner\n",
    "best_model = df_results.iloc[0]\n",
    "print(f\"\\n BEST PERFORMING MODEL:\")\n",
    "print(f\"   Model: {best_model['Model']}\")\n",
    "print(f\"   Test Accuracy: {best_model['Accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {best_model['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1404b1",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\"> Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6359e",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> distilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "039c87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "90ea874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5493\n"
     ]
    }
   ],
   "source": [
    "# 1. Load your dataset\n",
    "df_training = pd.read_csv(r\"C:\\DSML bootcamp\\Week7\\project-3-nlp\\dataset\\training_data.csv\", sep=\"\\t\", header=None, names=[\"label\", \"headline\"])\n",
    "df_training = df_training.dropna()\n",
    "df_training[\"label\"] = df_training[\"label\"].astype(int)\n",
    "\n",
    "# 2. Use a transformer pipeline (zero-shot or fine-tuned for sequence classification)\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", truncation=True)\n",
    "\n",
    "# 3. Run predictions\n",
    "preds = []\n",
    "for text in df_training[\"headline\"]:\n",
    "    result = classifier(text)[0]\n",
    "    label = 1 if result[\"label\"] == \"POSITIVE\" else 0\n",
    "    preds.append(label)\n",
    "\n",
    "# 4. Accuracy\n",
    "acc = accuracy_score(df_training[\"label\"], preds)\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea051a4",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #A7C7E7;\"> Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f718c5f",
   "metadata": {},
   "source": [
    "-   In this section we want to train the Pre-trained Model BERT and fit it with our data in order to generate better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6427f4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports successful!\n",
      "Accelerate version: 1.10.1\n",
      "Transformers version: 4.56.0\n"
     ]
    }
   ],
   "source": [
    "# Run this to test everything is working:\n",
    "import accelerate\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "print(\"✅ All imports successful!\")\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cdda7235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version: 1.10.1\n",
      "✅ Trainer imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test if accelerate imports correctly\n",
    "import accelerate\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")\n",
    "\n",
    "# Test if Trainer can import\n",
    "from transformers import Trainer\n",
    "print(\"✅ Trainer imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b6895316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_distilbert_truthminer_tabs.py - FIXED VERSION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split  # Add this import\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c9a58357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Paths (adjust if needed) ----------\n",
    "TRAIN_PATH = \"C:/DSML bootcamp/Week7/project-3-nlp/dataset/training_data.csv\"\n",
    "TEST_PATH  = \"C:/DSML bootcamp/Week7/project-3-nlp/dataset/testing_data.csv\"\n",
    "SUBMIT_OUT = \"C:/DSML bootcamp/Week7/project-3-nlp/dataset/testing_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f3970bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TSVs (no header)...\n",
      "Training data: (34152, 2)\n",
      "Label distribution: {0: 17572, 1: 16580}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Columns & model --\n",
    "# ---------- Config ----------\n",
    "TEXT_COL   = \"headline\"\n",
    "LABEL_COL  = \"label\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN    = 256\n",
    "VAL_SIZE   = 0.2   # 👈 80/20 split (change this to 0.1 for 90/10, etc.)\n",
    "\n",
    "print(\"Loading TSVs (no header)...\")\n",
    "data_train = pd.read_csv(TRAIN_PATH, sep=\"\\t\", header=None, names=[LABEL_COL, TEXT_COL])\n",
    "data_test  = pd.read_csv(TEST_PATH,  sep=\"\\t\", header=None, names=[LABEL_COL, TEXT_COL])\n",
    "\n",
    "# Sanity checks\n",
    "assert TEXT_COL in data_train.columns and LABEL_COL in data_train.columns\n",
    "assert TEXT_COL in data_test.columns  and LABEL_COL in data_test.columns\n",
    "assert set(data_train[LABEL_COL].unique()).issubset({0,1}), \"Training labels must be 0/1.\"\n",
    "\n",
    "print(f\"Training data: {data_train.shape}\")\n",
    "print(f\"Label distribution: {data_train[LABEL_COL].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a119da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating stratified train/validation split...\n",
      "Train size: 30,736\n",
      "Validation size: 3,416\n",
      "Training label distribution: {0: 15814, 1: 14922}\n",
      "Validation label distribution: {0: 1758, 1: 1658}\n",
      "✅ Datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "# ---------- FIXED: Build HF Datasets + validation split (90/10) ----------\n",
    "print(\"Creating stratified train/validation split...\")\n",
    "\n",
    "# Use sklearn for stratified splitting (this always works)\n",
    "train_data, val_data = train_test_split(\n",
    "    data_train,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=data_train[LABEL_COL]\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_data):,}\")\n",
    "print(f\"Validation size: {len(val_data):,}\")\n",
    "print(\"Training label distribution:\", train_data[LABEL_COL].value_counts().to_dict())\n",
    "print(\"Validation label distribution:\", val_data[LABEL_COL].value_counts().to_dict())\n",
    "\n",
    "# Create HF datasets from the split data\n",
    "hf_train = Dataset.from_pandas(train_data[[TEXT_COL, LABEL_COL]], preserve_index=False)\n",
    "hf_val = Dataset.from_pandas(val_data[[TEXT_COL, LABEL_COL]], preserve_index=False)\n",
    "hf_ds = DatasetDict(train=hf_train, validation=hf_val)\n",
    "\n",
    "# Test dataset for inference (ignore its 'label' values = 2)\n",
    "hf_test = Dataset.from_pandas(data_test[[TEXT_COL]], preserve_index=False)\n",
    "\n",
    "print(\"✅ Datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81583775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 30736/30736 [00:01<00:00, 23315.90 examples/s]\n",
      "Map: 100%|██████████| 3416/3416 [00:00<00:00, 31357.84 examples/s]\n",
      "Map: 100%|██████████| 9984/9984 [00:00<00:00, 34272.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------- Tokenizer ----------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tok_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[TEXT_COL],\n",
    "        truncation=True,\n",
    "        padding=False,      # dynamic padding via collator\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "cols_to_remove = [c for c in hf_ds[\"train\"].column_names if c not in [TEXT_COL, LABEL_COL]]\n",
    "tok_trainval = hf_ds.map(tok_fn, batched=True, remove_columns=cols_to_remove)\n",
    "tok_trainval = tok_trainval.rename_column(LABEL_COL, \"labels\")\n",
    "tok_trainval.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "tok_test = hf_test.map(tok_fn, batched=True)\n",
    "tok_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fa615f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ---------- Model ----------\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "# ---------- Metrics ----------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n",
    "\n",
    "print(\"Using device:\", \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4ecbb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naatt\\AppData\\Local\\Temp\\ipykernel_19996\\829706027.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ---------- Training args (M3/MPS friendly) ----------\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"runs/distilbert_truthminer\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,      # increase to 16 if memory allows\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,                 # a bit more training than 3\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=0,           # safer on MPS\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_trainval[\"train\"],\n",
    "    eval_dataset=tok_trainval[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "print(\"🚀 Starting training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "66443e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naatt\\anaconda3\\envs\\newnlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15368' max='15368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15368/15368 1:43:51, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.063437</td>\n",
       "      <td>0.983899</td>\n",
       "      <td>0.984876</td>\n",
       "      <td>0.981906</td>\n",
       "      <td>0.983389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.066949</td>\n",
       "      <td>0.988290</td>\n",
       "      <td>0.982122</td>\n",
       "      <td>0.993969</td>\n",
       "      <td>0.988010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.114554</td>\n",
       "      <td>0.984778</td>\n",
       "      <td>0.989038</td>\n",
       "      <td>0.979493</td>\n",
       "      <td>0.984242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108051</td>\n",
       "      <td>0.986827</td>\n",
       "      <td>0.986136</td>\n",
       "      <td>0.986731</td>\n",
       "      <td>0.986434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naatt\\anaconda3\\envs\\newnlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\naatt\\anaconda3\\envs\\newnlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\naatt\\anaconda3\\envs\\newnlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\naatt\\anaconda3\\envs\\newnlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'eval_loss': 0.06694863736629486, 'eval_accuracy': 0.9882903981264637, 'eval_precision': 0.9821215733015495, 'eval_recall': 0.9939686369119421, 'eval_f1': 0.988009592326139, 'eval_runtime': 25.885, 'eval_samples_per_second': 131.968, 'eval_steps_per_second': 8.267, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Train & evaluate ----------\n",
    "trainer.train()\n",
    "val_metrics = trainer.evaluate()\n",
    "print(\"Validation metrics:\", val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f81146ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naatt\\anaconda3\\envs\\newnlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# ---------- Predict test ----------\n",
    "print(\"Making predictions on test data...\")\n",
    "pred = trainer.predict(tok_test)\n",
    "test_labels = np.argmax(pred.predictions, axis=-1)  # 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "51d607e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions → C:/DSML bootcamp/Week7/project-3-nlp/dataset/testing_predictions.csv\n",
      "Prediction distribution: {1: 5032, 0: 4952}\n",
      "📝 SAVE THIS AS YOUR FIXED SCRIPT:\n",
      "Copy the complete code above to replace your current script\n"
     ]
    }
   ],
   "source": [
    "# ---------- Write submission in the SAME format as input ----------\n",
    "submit_df = data_test.copy()\n",
    "submit_df[LABEL_COL] = test_labels\n",
    "submit_df = submit_df[[LABEL_COL, TEXT_COL]]  # ensure order\n",
    "\n",
    "submit_df.to_csv(SUBMIT_OUT, sep=\"\\t\", header=False, index=False)\n",
    "print(f\"✅ Saved predictions → {SUBMIT_OUT}\")\n",
    "print(f\"Prediction distribution: {pd.Series(test_labels).value_counts().to_dict()}\")\n",
    "print(\"📝 SAVE THIS AS YOUR FIXED SCRIPT:\")\n",
    "print(\"Copy the complete code above to replace your current script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9a9fd",
   "metadata": {},
   "source": [
    "## <span style=\"color: #00FFFF;\"> Test Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ec16f",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">Loading the Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0742aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(r\"C:\\DSML bootcamp\\Week7\\project-3-nlp\\dataset\\testing_data.csv\", sep=\"\\t\", header=None, names=[\"label\", \"headline\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "15ab15f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>copycat muslim terrorist arrested with assault...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>germany's fdp look to fill schaeuble's big shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>u.n. seeks 'massive' aid boost amid rohingya '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>2</td>\n",
       "      <td>boom! fox news leftist chris wallace attempts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>2</td>\n",
       "      <td>here it is: list of democrat hypocrites who vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>2</td>\n",
       "      <td>new fires ravage rohingya villages in northwes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>2</td>\n",
       "      <td>meals on wheels shuts the lyin‚ lefties up wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>2</td>\n",
       "      <td>brilliant! tucker carlson and ayaan hirsi ali ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9984 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           headline\n",
       "0        2  copycat muslim terrorist arrested with assault...\n",
       "1        2  wow! chicago protester caught on camera admits...\n",
       "2        2   germany's fdp look to fill schaeuble's big shoes\n",
       "3        2  mi school sends welcome back packet warning ki...\n",
       "4        2  u.n. seeks 'massive' aid boost amid rohingya '...\n",
       "...    ...                                                ...\n",
       "9979     2  boom! fox news leftist chris wallace attempts ...\n",
       "9980     2  here it is: list of democrat hypocrites who vo...\n",
       "9981     2  new fires ravage rohingya villages in northwes...\n",
       "9982     2  meals on wheels shuts the lyin‚ lefties up wit...\n",
       "9983     2  brilliant! tucker carlson and ayaan hirsi ali ...\n",
       "\n",
       "[9984 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe8d2a",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">X y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3c37ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_test[\"headline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730db83f",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d185b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"headline_cleaned\"] = data_test[\"headline\"].apply(clean_single_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "18465cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "      <th>headline_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>copycat muslim terrorist arrested with assault...</td>\n",
       "      <td>copycat muslim terrorist arrested assault weapons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "      <td>wow ! chicago protester caught camera admits v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>germany's fdp look to fill schaeuble's big shoes</td>\n",
       "      <td>germany 's fdp look fill schaeuble 's big shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>u.n. seeks 'massive' aid boost amid rohingya '...</td>\n",
       "      <td>u.n. seeks  amassive ' aid boost amid rohingya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>2</td>\n",
       "      <td>boom! fox news leftist chris wallace attempts ...</td>\n",
       "      <td>boom ! fox news leftist chris wallace attempts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>2</td>\n",
       "      <td>here it is: list of democrat hypocrites who vo...</td>\n",
       "      <td>: list democrat hypocrites voted filibuster gw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>2</td>\n",
       "      <td>new fires ravage rohingya villages in northwes...</td>\n",
       "      <td>new fires ravage rohingya villages northwest m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>2</td>\n",
       "      <td>meals on wheels shuts the lyin‚ lefties up wit...</td>\n",
       "      <td>meals wheels shuts lyin‚ lefties truth moveon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>2</td>\n",
       "      <td>brilliant! tucker carlson and ayaan hirsi ali ...</td>\n",
       "      <td>brilliant ! tucker carlson ayaan hirsi ali dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           headline  \\\n",
       "0        2  copycat muslim terrorist arrested with assault...   \n",
       "1        2  wow! chicago protester caught on camera admits...   \n",
       "2        2   germany's fdp look to fill schaeuble's big shoes   \n",
       "3        2  mi school sends welcome back packet warning ki...   \n",
       "4        2  u.n. seeks 'massive' aid boost amid rohingya '...   \n",
       "...    ...                                                ...   \n",
       "9979     2  boom! fox news leftist chris wallace attempts ...   \n",
       "9980     2  here it is: list of democrat hypocrites who vo...   \n",
       "9981     2  new fires ravage rohingya villages in northwes...   \n",
       "9982     2  meals on wheels shuts the lyin‚ lefties up wit...   \n",
       "9983     2  brilliant! tucker carlson and ayaan hirsi ali ...   \n",
       "\n",
       "                                       headline_cleaned  \n",
       "0     copycat muslim terrorist arrested assault weapons  \n",
       "1     wow ! chicago protester caught camera admits v...  \n",
       "2       germany 's fdp look fill schaeuble 's big shoes  \n",
       "3     mi school sends welcome back packet warning ki...  \n",
       "4     u.n. seeks  amassive ' aid boost amid rohingya...  \n",
       "...                                                 ...  \n",
       "9979  boom ! fox news leftist chris wallace attempts...  \n",
       "9980  : list democrat hypocrites voted filibuster gw...  \n",
       "9981  new fires ravage rohingya villages northwest m...  \n",
       "9982  meals wheels shuts lyin‚ lefties truth moveon....  \n",
       "9983  brilliant ! tucker carlson ayaan hirsi ali dis...  \n",
       "\n",
       "[9984 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c3e8b",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03913bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_test[\"headline_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "62f3b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bdb124",
   "metadata": {},
   "source": [
    "### <span style=\"color: #30D5C8;\">Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "03f00d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = svm.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0408c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"label\"] = Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "799280ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "      <th>headline_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>copycat muslim terrorist arrested with assault...</td>\n",
       "      <td>copycat muslim terrorist arrested assault weapons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "      <td>wow ! chicago protester caught camera admits v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>germany's fdp look to fill schaeuble's big shoes</td>\n",
       "      <td>germany 's fdp look fill schaeuble 's big shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>u.n. seeks 'massive' aid boost amid rohingya '...</td>\n",
       "      <td>u.n. seeks  amassive ' aid boost amid rohingya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0</td>\n",
       "      <td>boom! fox news leftist chris wallace attempts ...</td>\n",
       "      <td>boom ! fox news leftist chris wallace attempts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>1</td>\n",
       "      <td>here it is: list of democrat hypocrites who vo...</td>\n",
       "      <td>: list democrat hypocrites voted filibuster gw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>1</td>\n",
       "      <td>new fires ravage rohingya villages in northwes...</td>\n",
       "      <td>new fires ravage rohingya villages northwest m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0</td>\n",
       "      <td>meals on wheels shuts the lyin‚ lefties up wit...</td>\n",
       "      <td>meals wheels shuts lyin‚ lefties truth moveon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>brilliant! tucker carlson and ayaan hirsi ali ...</td>\n",
       "      <td>brilliant ! tucker carlson ayaan hirsi ali dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           headline  \\\n",
       "0         0  copycat muslim terrorist arrested with assault...   \n",
       "1         0  wow! chicago protester caught on camera admits...   \n",
       "2         0   germany's fdp look to fill schaeuble's big shoes   \n",
       "3         0  mi school sends welcome back packet warning ki...   \n",
       "4         1  u.n. seeks 'massive' aid boost amid rohingya '...   \n",
       "...     ...                                                ...   \n",
       "9979      0  boom! fox news leftist chris wallace attempts ...   \n",
       "9980      1  here it is: list of democrat hypocrites who vo...   \n",
       "9981      1  new fires ravage rohingya villages in northwes...   \n",
       "9982      0  meals on wheels shuts the lyin‚ lefties up wit...   \n",
       "9983      0  brilliant! tucker carlson and ayaan hirsi ali ...   \n",
       "\n",
       "                                       headline_cleaned  \n",
       "0     copycat muslim terrorist arrested assault weapons  \n",
       "1     wow ! chicago protester caught camera admits v...  \n",
       "2       germany 's fdp look fill schaeuble 's big shoes  \n",
       "3     mi school sends welcome back packet warning ki...  \n",
       "4     u.n. seeks  amassive ' aid boost amid rohingya...  \n",
       "...                                                 ...  \n",
       "9979  boom ! fox news leftist chris wallace attempts...  \n",
       "9980  : list democrat hypocrites voted filibuster gw...  \n",
       "9981  new fires ravage rohingya villages northwest m...  \n",
       "9982  meals wheels shuts lyin‚ lefties truth moveon....  \n",
       "9983  brilliant ! tucker carlson ayaan hirsi ali dis...  \n",
       "\n",
       "[9984 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
